{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "Collecting pybind11>=2.2\n",
      "  Using cached pybind11-2.6.2-py2.py3-none-any.whl (191 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\glase\\anaconda3\\lib\\site-packages (from fasttext) (50.3.1.post20201107)\n",
      "Requirement already satisfied: numpy in c:\\users\\glase\\anaconda3\\lib\\site-packages (from fasttext) (1.19.2)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py): started\n",
      "  Building wheel for fasttext (setup.py): finished with status 'done'\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-win_amd64.whl size=235144 sha256=b171b48fc736fa29f7ad3ca11f98c0471648cfe5baaa58d212b33385345a27e7\n",
      "  Stored in directory: c:\\users\\glase\\appdata\\local\\pip\\cache\\wheels\\4e\\ca\\bf\\b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
      "Successfully built fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.2 pybind11-2.6.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Subprocess output does not appear to be encoded as cp1252\n",
      "  WARNING: Subprocess output does not appear to be encoded as cp1252\n",
      "  WARNING: Subprocess output does not appear to be encoded as cp1252\n"
     ]
    }
   ],
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import emoji\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Jeg tror det vil være dejlig køligt, men jeg v...\n",
       "1       Så kommer de nok til at investere i en ny cyke...\n",
       "2       Nu er det jo også de Ikea-aber der har lavet s...\n",
       "3       128 Varme emails, er vi enige om at det er sex...\n",
       "4       Desværre tyder det på, at amerikanerne er helt...\n",
       "                              ...                        \n",
       "2955    Har sgu lidt en anelse om... det her kunne mås...\n",
       "2956    Ind og ruske tremmer med hende,Den syge kælling!!\n",
       "2957                                             fedtmule\n",
       "2958                                    ##HAR I HØRT DET?\n",
       "2959    Kommer det bag på nogen? Det er jo fucking var...\n",
       "Name: tweet, Length: 2960, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Danish/Danish/offenseval-da-training-v1.tsv\", sep='\\t')[:-1]\n",
    "\n",
    "texts = data[\"tweet\"].apply(str)\n",
    "labels = data[\"subtask_a\"].apply(str)\n",
    "#print(data.loc[2883])\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@USER',\n",
       " 'næste',\n",
       " 'gang',\n",
       " 'pastaen',\n",
       " 'er',\n",
       " 'brændt',\n",
       " 'på',\n",
       " '!',\n",
       " ':face_with_tears_of_joy:',\n",
       " 'det',\n",
       " 'jo',\n",
       " 'sygt...']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization\n",
    "texts_tokenized = []\n",
    "for el in texts:\n",
    "    texts_tokenized.append([emoji.demojize(el) for el in el.split()]) #nltk.word_tokenize(el)\n",
    "\n",
    "    \n",
    "texts_tokenized[2883]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@user', 'næste', 'gang', 'pastaen', 'er', 'brændt', 'på', 'det', 'jo', 'sygt']\n"
     ]
    }
   ],
   "source": [
    "#normalization\n",
    "texts_normalized = []\n",
    "for sent in texts_tokenized:\n",
    "    # remove emojis\n",
    "    sent = [el.lower() for el in sent if not bool(re.search(r\":.*:\", el))] #or replace with just name?\n",
    "    # remove repeating characters\n",
    "    sent = [re.sub(r\"(.)\\1{2,}\", r\"\\1\", el) for el in sent]\n",
    "    sent = [re.sub(r\"[!?\\(\\)\\\\&.,:><_#\\[\\]/]+\", \"\", el)for el in sent]\n",
    "    texts_normalized.append([el for el in sent if el != \"\"])\n",
    "        \n",
    "print(texts_normalized[2883])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3131</td>\n",
       "      <td>jeg tror det vil være dejlig køligt men jeg vi...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>711</td>\n",
       "      <td>så kommer de nok til at investere i en ny cyke...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500</td>\n",
       "      <td>nu er det jo også de ikea-aber der har lavet s...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2678</td>\n",
       "      <td>128 varme emails er vi enige om at det er sext...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>784</td>\n",
       "      <td>desværre tyder det på at amerikanerne er helt ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>170</td>\n",
       "      <td>har sgu lidt en anelse om det her kunne måske ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>1226</td>\n",
       "      <td>ind og ruske tremmer med hendeden syge kælling</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>2596</td>\n",
       "      <td>fedtmule</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>1802</td>\n",
       "      <td>har i hørt det</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>2809</td>\n",
       "      <td>kommer det bag på nogen det er jo fucking varm...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2960 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet subtask_a\n",
       "0     3131  jeg tror det vil være dejlig køligt men jeg vi...       NOT\n",
       "1      711  så kommer de nok til at investere i en ny cyke...       NOT\n",
       "2     2500  nu er det jo også de ikea-aber der har lavet s...       OFF\n",
       "3     2678  128 varme emails er vi enige om at det er sext...       NOT\n",
       "4      784  desværre tyder det på at amerikanerne er helt ...       NOT\n",
       "...    ...                                                ...       ...\n",
       "2955   170  har sgu lidt en anelse om det her kunne måske ...       NOT\n",
       "2956  1226     ind og ruske tremmer med hendeden syge kælling       OFF\n",
       "2957  2596                                           fedtmule       NOT\n",
       "2958  1802                                     har i hørt det       NOT\n",
       "2959  2809  kommer det bag på nogen det er jo fucking varm...       OFF\n",
       "\n",
       "[2960 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_normalized2 = [\" \".join(el) for el in texts_normalized]\n",
    "texts_normalized3 = pd.DataFrame(texts_normalized2, columns=[\"tweet\"])\n",
    "texts_normalized3\n",
    "data[\"tweet\"] = texts_normalized2\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       jeg tror det vil være dejlig køligt men jeg vi...\n",
       " 1       så kommer de nok til at investere i en ny cyke...\n",
       " 2       nu er det jo også de ikea-aber der har lavet s...\n",
       " 3       128 varme emails er vi enige om at det er sext...\n",
       " 4       desværre tyder det på at amerikanerne er helt ...\n",
       "                               ...                        \n",
       " 2955    har sgu lidt en anelse om det her kunne måske ...\n",
       " 2956       ind og ruske tremmer med hendeden syge kælling\n",
       " 2957                                             fedtmule\n",
       " 2958                                       har i hørt det\n",
       " 2959    kommer det bag på nogen det er jo fucking varm...\n",
       " Name: tweet, Length: 2960, dtype: object,\n",
       " 0       NOT\n",
       " 1       NOT\n",
       " 2       OFF\n",
       " 3       NOT\n",
       " 4       NOT\n",
       "        ... \n",
       " 2955    NOT\n",
       " 2956    OFF\n",
       " 2957    NOT\n",
       " 2958    NOT\n",
       " 2959    OFF\n",
       " Name: subtask_a, Length: 2960, dtype: object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data[\"tweet\"].apply(str)\n",
    "texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2734    jeg vil foreslå to andre billeder af københavn...\n",
       " 2886    og der bliver stadigt flereurl danmark længe leve\n",
       " 2738                                                  lol\n",
       " 2937    ah og vi har allerede fået bygget en mur mod i...\n",
       " 2671    vi må da sige han går da all in når man skal t...\n",
       "                               ...                        \n",
       " 1147    det er jo ikke sjovt nogen ting spøger man bar...\n",
       " 2154                                  det har du os rat i\n",
       " 1766                          grønt er altså for bornholm\n",
       " 1122    de skal bare kvæles langsomt så de ligger stil...\n",
       " 1346    syntes man begynder at høre mere om partering ...\n",
       " Name: tweet, Length: 2220, dtype: object,\n",
       " 418     ikke noget andre kvinder ikke har men ser bedr...\n",
       " 1224    foretrækker dog isterningebakken den kan bruge...\n",
       " 1617    troede at vores flag altid brandte det gør det...\n",
       " 1745                                                 mere\n",
       " 2139                        også kendt som opium med brus\n",
       "                               ...                        \n",
       " 2529          fantastisk at du gad lave al den research d\n",
       " 2883    @user næste gang pastaen er brændt på det jo sygt\n",
       " 1678    ”vi kan jo ikke faktatjekke alting og når det ...\n",
       " 375                      jeg gad godt have det der pr job\n",
       " 219     jeg leger lige djævelens advokat jantelov er h...\n",
       " Name: tweet, Length: 740, dtype: object,\n",
       " 2734    NOT\n",
       " 2886    NOT\n",
       " 2738    NOT\n",
       " 2937    NOT\n",
       " 2671    NOT\n",
       "        ... \n",
       " 1147    NOT\n",
       " 2154    NOT\n",
       " 1766    NOT\n",
       " 1122    NOT\n",
       " 1346    NOT\n",
       " Name: subtask_a, Length: 2220, dtype: object,\n",
       " 418     NOT\n",
       " 1224    NOT\n",
       " 1617    NOT\n",
       " 1745    NOT\n",
       " 2139    NOT\n",
       "        ... \n",
       " 2529    NOT\n",
       " 2883    NOT\n",
       " 1678    OFF\n",
       " 375     NOT\n",
       " 219     NOT\n",
       " Name: subtask_a, Length: 740, dtype: object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, test_size=0.25, random_state=123)\n",
    "texts_train, texts_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"Danish/Model/train.txt\"\n",
    "test_file = \"Danish/Model/test.txt\"\n",
    "with open(train_file, \"w\", encoding=\"utf8\") as f:\n",
    "    for label, tweet in zip(labels_train, texts_train):\n",
    "        f.write(f\"__label__{label} {tweet}\\n\")\n",
    "        \n",
    "with open(test_file, \"w\", encoding=\"utf8\") as f:\n",
    "    for label, tweet in zip(labels_test, texts_test):\n",
    "        f.write(f\"__label__{label} {tweet}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('__label__NOT',), array([0.95414782])) (('__label__NOT',), array([0.89170223])) (740, 0.9135135135135135, 0.9135135135135135)\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(\"ikke noget andre kvinder ikke har men ser bedre ud med tøj på\"),\n",
    "model.predict(\"de skulle have en røvfuld så stor at de ikke ved hvad de selv hedder og så skal de eller deres forældre selv betale regningen\"),\n",
    "model.test(test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=train_file, epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('__label__NOT',), array([0.99845523])) (('__label__NOT',), array([0.98049331])) (740, 0.9256756756756757, 0.9256756756756757)\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(\"ikke noget andre kvinder ikke har men ser bedre ud med tøj på\"),\n",
    "model.predict(\"de skulle have en røvfuld så stor at de ikke ved hvad de selv hedder og så skal de eller deres forældre selv betale regningen\"),\n",
    "model.test(test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fasttext.FastText._FastText object at 0x000002239175FF28>\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(input=train_file, epoch=25, lr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('__label__NOT',), array([0.99983138])) (('__label__NOT',), array([0.99922681])) (740, 0.9243243243243243, 0.9243243243243243)\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(\"ikke noget andre kvinder ikke har men ser bedre ud med tøj på\"),\n",
    "model.predict(\"de skulle have en røvfuld så stor at de ikke ved hvad de selv hedder og så skal de eller deres forældre selv betale regningen\"),\n",
    "model.test(test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=train_file, epoch=1000, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('__label__NOT',), array([1.00000584])) (('__label__OFF',), array([0.99513948])) (740, 0.9216216216216216, 0.9216216216216216)\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(\"ikke noget andre kvinder ikke har men ser bedre ud med tøj på\"),\n",
    "model.predict(\"hvad med i stedet for at anholde ham så give ham et lift til hotellet i stedet for de er skøre de svenskere\"),\n",
    "model.test(test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9216216216216216, 0.0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.predict(\"hvad med i stedet for at anholde ham så give ham et lift til hotellet i stedet for de er skøre de svenskere\")[0][0][-3:]\n",
    "tp = 0\n",
    "f = 0\n",
    "all = 0\n",
    "pred = [model.predict(t)[0][0][-3:] for t in texts_test]\n",
    "pn = []\n",
    "for el in pred:\n",
    "    if el == \"OFF\":\n",
    "        pn.append(1)\n",
    "    else:\n",
    "        pn.append(0)\n",
    "\n",
    "tn = []\n",
    "for el in texts_test:\n",
    "    if el == \"OFF\":\n",
    "        tn.append(1)\n",
    "    else:\n",
    "        tn.append(0)\n",
    "\n",
    "accuracy_score(labels_test, pred), f1_score(tn, pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682 58 740\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "f = 0\n",
    "all = 0\n",
    "for t, l in zip(texts_test, labels_test):\n",
    "    pred_label = model.predict(t)[0][0][-3:]\n",
    "    if pred_label == l:\n",
    "        tp += 1\n",
    "        all += 1\n",
    "    else:\n",
    "        f += 1\n",
    "        all += 1\n",
    "print(tp, f, all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
