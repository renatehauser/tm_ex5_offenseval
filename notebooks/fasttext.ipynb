{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in c:\\users\\glase\\anaconda3\\lib\\site-packages (0.9.2)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\glase\\anaconda3\\lib\\site-packages (from fasttext) (50.3.1.post20201107)\n",
      "Requirement already satisfied: pybind11>=2.2 in c:\\users\\glase\\anaconda3\\lib\\site-packages (from fasttext) (2.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\glase\\anaconda3\\lib\\site-packages (from fasttext) (1.19.2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import emoji\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Jeg tror det vil være dejlig køligt, men jeg v...\n",
       "1       Så kommer de nok til at investere i en ny cyke...\n",
       "2       Nu er det jo også de Ikea-aber der har lavet s...\n",
       "3       128 Varme emails, er vi enige om at det er sex...\n",
       "4       Desværre tyder det på, at amerikanerne er helt...\n",
       "                              ...                        \n",
       "2955    Har sgu lidt en anelse om... det her kunne mås...\n",
       "2956    Ind og ruske tremmer med hende,Den syge kælling!!\n",
       "2957                                             fedtmule\n",
       "2958                                    ##HAR I HØRT DET?\n",
       "2959    Kommer det bag på nogen? Det er jo fucking var...\n",
       "Name: tweet, Length: 2960, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../Danish/Danish/offenseval-da-training-v1.tsv\", sep='\\t')[:-1]\n",
    "\n",
    "texts = data[\"tweet\"].apply(str)\n",
    "labels = data[\"subtask_a\"].apply(str)\n",
    "#print(data.loc[2883])\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@user',\n",
       " 'næste',\n",
       " 'gang',\n",
       " 'pastaen',\n",
       " 'er',\n",
       " 'brændt',\n",
       " 'på',\n",
       " '!',\n",
       " ':face_with_tears_of_joy:',\n",
       " 'det',\n",
       " 'jo',\n",
       " 'sygt...']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization and replacing emojis\n",
    "texts_tokenized = []\n",
    "for el in texts:\n",
    "    texts_tokenized.append([emoji.demojize(el).lower() for el in el.split()]) #nltk.word_tokenize(el)\n",
    "\n",
    "    \n",
    "texts_tokenized[2883]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@user', 'næste', 'gang', 'pastaen', 'er', 'brændt', 'på', '!', ':face_with_tears_of_joy:', 'det', 'jo', 'sygt.']\n"
     ]
    }
   ],
   "source": [
    "#normalization\n",
    "texts_normalized = []\n",
    "for sent in texts_tokenized:\n",
    "    \n",
    "    # remove emojis\n",
    "    #sent = [el for el in sent if not bool(re.search(r\":.*:\", el))] #or replace with just name?\n",
    "    \n",
    "    # remove repeating characters\n",
    "    sent = [re.sub(r\"(.)\\1{2,}\", r\"\\1\", el) for el in sent]\n",
    "    \n",
    "    # remove emojis\n",
    "    #sent = [re.sub(r\"[!?\\(\\)\\\\&.,:><_#\\[\\]/]+\", \"\", el)for el in sent]\n",
    "    \n",
    "    texts_normalized.append([el for el in sent if el != \"\"])\n",
    "        \n",
    "print(texts_normalized[2883])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3131</td>\n",
       "      <td>jeg tror det vil være dejlig køligt, men jeg v...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>711</td>\n",
       "      <td>så kommer de nok til at investere i en ny cyke...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500</td>\n",
       "      <td>nu er det jo også de ikea-aber der har lavet s...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2678</td>\n",
       "      <td>128 varme emails, er vi enige om at det er sex...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>784</td>\n",
       "      <td>desværre tyder det på, at amerikanerne er helt...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>170</td>\n",
       "      <td>har sgu lidt en anelse om. det her kunne måske...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>1226</td>\n",
       "      <td>ind og ruske tremmer med hende,den syge kælling!!</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>2596</td>\n",
       "      <td>fedtmule</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>1802</td>\n",
       "      <td>##har i hørt det?</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>2809</td>\n",
       "      <td>kommer det bag på nogen? det er jo fucking var...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2960 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet subtask_a\n",
       "0     3131  jeg tror det vil være dejlig køligt, men jeg v...       NOT\n",
       "1      711  så kommer de nok til at investere i en ny cyke...       NOT\n",
       "2     2500  nu er det jo også de ikea-aber der har lavet s...       OFF\n",
       "3     2678  128 varme emails, er vi enige om at det er sex...       NOT\n",
       "4      784  desværre tyder det på, at amerikanerne er helt...       NOT\n",
       "...    ...                                                ...       ...\n",
       "2955   170  har sgu lidt en anelse om. det her kunne måske...       NOT\n",
       "2956  1226  ind og ruske tremmer med hende,den syge kælling!!       OFF\n",
       "2957  2596                                           fedtmule       NOT\n",
       "2958  1802                                  ##har i hørt det?       NOT\n",
       "2959  2809  kommer det bag på nogen? det er jo fucking var...       OFF\n",
       "\n",
       "[2960 rows x 3 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the preprocessed texts back into the dataframe\n",
    "texts_normalized2 = [\" \".join(el) for el in texts_normalized]\n",
    "data[\"tweet\"] = texts_normalized2\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       jeg tror det vil være dejlig køligt, men jeg v...\n",
       " 1       så kommer de nok til at investere i en ny cyke...\n",
       " 2       nu er det jo også de ikea-aber der har lavet s...\n",
       " 3       128 varme emails, er vi enige om at det er sex...\n",
       " 4       desværre tyder det på, at amerikanerne er helt...\n",
       "                               ...                        \n",
       " 2955    har sgu lidt en anelse om. det her kunne måske...\n",
       " 2956    ind og ruske tremmer med hende,den syge kælling!!\n",
       " 2957                                             fedtmule\n",
       " 2958                                    ##har i hørt det?\n",
       " 2959    kommer det bag på nogen? det er jo fucking var...\n",
       " Name: tweet, Length: 2960, dtype: object,\n",
       " 0       NOT\n",
       " 1       NOT\n",
       " 2       OFF\n",
       " 3       NOT\n",
       " 4       NOT\n",
       "        ... \n",
       " 2955    NOT\n",
       " 2956    OFF\n",
       " 2957    NOT\n",
       " 2958    NOT\n",
       " 2959    OFF\n",
       " Name: subtask_a, Length: 2960, dtype: object)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data[\"tweet\"].apply(str)\n",
    "texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, test_size=0.25, random_state=123)\n",
    "#texts_train, texts_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write train and test data into files. label and tweet are separated by \\t\n",
    "train_file = \"../../Danish/Model/train.txt\"\n",
    "test_file = \"../../Danish/Model/test.txt\"\n",
    "with open(train_file, \"w\", encoding=\"utf8\") as f:\n",
    "    for label, tweet in zip(labels_train, texts_train):\n",
    "        f.write(f\"__label__{label}\\t{tweet}\\n\")\n",
    "        \n",
    "with open(test_file, \"w\", encoding=\"utf8\") as f:\n",
    "    for label, tweet in zip(labels_test, texts_test):\n",
    "        f.write(f\"__label__{label}\\t{tweet}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train different models and add them to a list\n",
    "models = []\n",
    "model1 = fasttext.train_supervised(input=train_file)\n",
    "models.append(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = fasttext.train_supervised(input=train_file, epoch=25)\n",
    "models.append(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = fasttext.train_supervised(input=train_file, epoch=25, lr=0.3)\n",
    "models.append(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = fasttext.train_supervised(input=train_file, epoch=100, lr=0.1)\n",
    "models.append(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use all models to predict the test file\n",
    "predictions = []\n",
    "for model in models:\n",
    "    with open(test_file, \"r\", encoding=\"utf8\") as f:\n",
    "        pred_labels = []\n",
    "        true_labels = []\n",
    "        for line in f.readlines():\n",
    "            l, t = line.split(\"\\t\")\n",
    "            true_labels.append(l)\n",
    "            pred = model.predict(t.strip(\"\\n\"))\n",
    "            pred_labels.append(pred[0][0])\n",
    "    predictions.append((pred_labels, true_labels))\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(pred_label,true_label):\n",
    "    '''\n",
    "    Returns accuracy and f1 score metrics for evaluation\n",
    "    '''\n",
    "    accuracy=accuracy_score(true_label,pred_label)\n",
    "    f1score=f1_score(true_label,pred_label,average='macro')\n",
    "    precision= precision_score(true_label, pred_label,average='macro')\n",
    "    recall=recall_score(true_label, pred_label,average='macro')\n",
    "    \n",
    "    return (accuracy,precision,recall,f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1:\n",
      "\tAccuracy: 0.9121621621621622\n",
      "\tPrecision: 0.9557220708446866\n",
      "\tRecall: 0.5422535211267605\n",
      "\tF1score: 0.5547574307374735\n",
      "Model2:\n",
      "\tAccuracy: 0.9202702702702703\n",
      "\tPrecision: 0.8213282504012841\n",
      "\tRecall: 0.634865997178888\n",
      "\tF1score: 0.6806588696523527\n",
      "Model3:\n",
      "\tAccuracy: 0.9202702702702703\n",
      "\tPrecision: 0.8147887323943661\n",
      "\tRecall: 0.6411608665445588\n",
      "\tF1score: 0.686528478808722\n",
      "Model4:\n",
      "\tAccuracy: 0.9081081081081082\n",
      "\tPrecision: 0.7339971550497866\n",
      "\tRecall: 0.6281395397797849\n",
      "\tF1score: 0.6604038440773135\n",
      "Best Model: <fasttext.FastText._FastText object at 0x000001F12A3142B0>: 0.686528478808722\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "i = 1\n",
    "maxf = 0\n",
    "for el in predictions:\n",
    "    metrics = evaluation_metrics(el[0], el[1])\n",
    "    if metrics[-1] >= maxf:\n",
    "        maxf = metrics[-1]\n",
    "        best_model = models[i-1]\n",
    "    print(f\"Model{i}:\\n\\tAccuracy: {metrics[0]}\\n\\tPrecision: {metrics[1]}\\n\\tRecall: {metrics[2]}\\n\\tF1score: {metrics[3]}\")\n",
    "    i+=1\n",
    "print(f\"Best Model: {best_model}: {maxf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('__label__NOT',), array([0.90585428]))\n",
      "(('__label__OFF',), array([0.88944393]))\n",
      "(('__label__OFF',), array([0.99604893]))\n",
      "(('__label__OFF',), array([0.98114443]))\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model.predict(\"hvad med i stedet for at anholde ham så give ham et lift til hotellet i stedet for de er skøre de svenskere\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: NOT, Pred: NOT\n",
      "\tjeg mener billedet kommer fra en kampagne af ddrjake. han streamer stadig på twitch og arbejder faktisk for paradox interactive, der har lavet spillet. den eneste skavank er at paradox er et svensk firma. fy da føj da.\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\tnogen der ved hvor man kan streame/downloade/købe filmen digitalt?\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\tsend dem hjem og luk ikke flere ind\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\tjeg var studerende på danmark fra usa i 1994 og kan stadig snakke noget dansk. jeg elsker danmark!\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\tfremragende tilbud hvor der både er lidt til ham og hende!\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\tjeg ville ønske, migmiger brugte grammatisk komma :( \"det er der, du tager fejl, drengo\" punktummet til slut er ikke så vigtigt.\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\tinte ens i danmark vill man dricka dansk glögg.\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\tgodt arbejde, op!\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\tjeg læste med det samme det første billede som \"pludder\".\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\tgg\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\truller med kjøller og kosten bakker snagvendt til osten popper dig som tørret majs tjubang-tjubang, duk dig splejs\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\t>og hvis vi slår svenskerne, bliver vi glade den eneste relevante målsætning.\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\tsynes hun har en okay pæn krop. men vil gerne se din gitte @user for den må være perfekt.\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\tgrinte en del over den, den er sgu meget sjov. synes også jeg har set mange have ondt i røven over ting. men er det noget nyt? det kan jo være folk altid har haft det sådan med forskellige ting, men de sociale medier bare har givet en kanal til folk at udtrykke deres meninger nemmere. siger hverken det ene eller andet, men synes ikke man bare skal skyde skylden på sociale medier. og hvem ved, det kan være folk også havde lige så ondt i røven for 100 år siden.\n",
      "\n",
      "True: NOT, Pred: NOT\n",
      "\ter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the best model on random samples\n",
    "import random\n",
    "with open(test_file, \"r\", encoding=\"utf8\") as f:\n",
    "    for el in random.sample(f.readlines(), 15):\n",
    "        l, t = el.split(\"\\t\")\n",
    "        true = l[-3:]\n",
    "        pred = best_model.predict(t.strip(\"\\n\"))[0][0][-3:]\n",
    "        print(f\"True: {true}, Pred: {pred}\\n\\t{t}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
